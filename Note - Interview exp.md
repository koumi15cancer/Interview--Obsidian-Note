**Mizuho Information & Research Institute Asia Pte. Ltd (Jan 2023 - Mar 2024) - Software Engineer Contractor:**

Working as a Software Engineer Contractor at Mizuho, I was entrusted with the Centralized Financial Report project, a pivotal initiative aimed at consolidating and analyzing financial data from multiple departments. My primary focus was on developing the frontend of the reporting web application and orchestrating the backend data processing pipeline.

**Project Details:**

- **Reporting Web Application Frontend:** I led the implementation of the reporting web application's frontend, ensuring an intuitive user interface that facilitated easy access to financial insights.
- **Data Processing from Multiple Department Sources:** Integrating data from various departments posed a significant challenge. I worked closely with stakeholders to understand their data requirements and devised strategies to streamline data extraction, transformation, and loading (ETL) processes.
- **Migration and Enhancement of Code:** To enhance system performance and scalability, I spearheaded the migration and optimization of code for load balancing and caching in memory. This involved refactoring legacy code and implementing modern caching techniques to minimize data retrieval latency.
- **CI/CD Workflow with .NET:** I established a robust CI/CD workflow using .NET, automating the build, testing, and deployment processes. Implementing a Command Query Responsibility Segregation (CQRS) architecture allowed us to separate read and write operations, optimizing database performance and enhancing data consistency.

---

**NEC Vietnam (Jan 2022 - Dec 2022) - Software Engineer:**

At NEC Vietnam, I played a key role in two significant projects: the EUC Data Hub and Minamori Rehab Streaming, where I leveraged my technical expertise to optimize data processing workflows and develop innovative streaming solutions.

**Project Details:**

- **EUC Data Hub Optimization:** In the EUC Data Hub project, I focused on optimizing data processing workflows by implementing chunk data processing and caching strategies on materialized views. This allowed us to efficiently handle large volumes of data while minimizing processing overhead.
- **Automated Data Migration and Version Control:** I developed customized bash scripts to automate data migration and version control of data models, ensuring seamless transitions between different system versions and maintaining data integrity throughout the process.
- **Minamori Rehab Streaming Proof of Concept:** In this project, I led the development of a proof of concept for streaming services between mobile and web applications using WebRTC and Node.js. This involved designing and implementing real-time communication protocols and integrating them seamlessly with existing frontend and backend systems.
- **Basic Frontend Development with React.js:** As part of the Minamori Rehab Streaming project, I also contributed to frontend development efforts using React.js, enhancing user interface responsiveness and interactivity.

---

**Zalopay (Internship):**

During my internship at Zalopay, I had the opportunity to contribute to the Minamori Rehab Streaming project, where I focused on optimizing data processing workflows and deploying Airflow DAGs to streamline data processing tasks.

**Project Details:**

- **Automated Data Quality Checks:** I implemented automated data quality checks to ensure data integrity and accuracy, reducing manual effort and minimizing the risk of data inconsistencies.
- **Process Optimization with PySpark:** Leveraging PySpark, I optimized data processing workflows by implementing partitioning and caching strategies, improving processing efficiency and reducing overall execution time.
- **Deployment and Implementation of Airflow DAGs:** I played a key role in deploying and implementing Airflow Directed Acyclic Graphs (DAGs) to automate and orchestrate data processing tasks. This involved designing workflow dependencies, scheduling tasks, and monitoring workflow execution to ensure timely and accurate data processing.

---

**Can you tell me about how you set up continuous integration in your last project?** In my last project, I implemented continuous integration using Jenkins. I configured Jenkins to automatically trigger builds whenever changes were pushed to the version control repository. Each build executed a series of automated tests, including unit tests, integration tests, and code analysis tools. Jenkins provided visibility into build status and test results, enabling early detection of issues and ensuring that the codebase remained stable.

---
**How have you contributed to a team’s codebase without being the owner/maintainer of it?** I have contributed to a team's codebase by:

- Reviewing pull requests and providing constructive feedback on code changes.
- Participating in code review sessions to identify and address potential issues or improvements.
- Collaborating with team members to implement new features, fix bugs, or refactor code.
- Writing documentation, creating coding standards, and sharing best practices to improve code quality and maintainability.



----

**Tell me about how you’ve worked with [insert different technology here].** I have experience working with various technologies, including [insert different technology here]. For example, I have utilized [insert different technology here] to [briefly describe the specific tasks or projects you have completed using that technology, highlighting your role and contributions].