### Summary of the Video: How to Ingest a New Data Source in Azure Data Factory

![[How to Ingest a New Data Source in Azure Data Factory.png]]

#### Introduction
The video explains the steps and considerations for ingesting a new data source in Azure Data Factory (ADF). It emphasizes the importance of asking the right questions and planning to avoid potential issues during data ingestion.

#### Key Concepts
1. **Identify the Data Source**:
   - **Type of Source**: Determine if it is a database, file, or API.
     - **Database**: Identify the type (SQL Server, Oracle, MySQL, etc.).
     - **File**: Determine the format (CSV, JSON, XML, Parquet, etc.) and storage location.
     - **API**: Identify the type (REST, GraphQL, etc.).
   - **Location**: Establish if the data is cloud-based or on-premises.

2. **Connection Approach**:
   - **Pull or Push**: Decide if the data will be pulled by ADF or pushed to ADF.
   - **Streaming or Batch**: Determine if the data source provides streaming data or batch data.

3. **Scheduling**:
   - **Ingestion Schedule**: Plan the schedule for data ingestion, considering the operational hours of the source system to avoid disruptions.

4. **Development Status**:
   - **Under Development**: Check if the data source is under active development and prone to changes.

5. **Connection Details**:
   - **How to Connect**: Identify necessary details like IP addresses, ports, protocols, URLs, server names, and database names.
   - **Networking**: Ensure line-of-sight and configure networking settings such as firewall whitelisting.

6. **Security**:
   - **Authentication**: Determine the method of authentication (user/password, access token, etc.).
   - **Authorization**: Ensure proper permissions are granted for accessing the data.

7. **Proof of Concept (POC)**:
   - **Quick Test**: Conduct a quick and dirty POC to verify connectivity and access before full implementation.

8. **Rate Limits and Throttling**:
   - **API Limits**: Check for rate limits and throttling policies that could impact data ingestion.

9. **Data Characteristics**:
   - **Data Type**: Identify if the data is master data, transactional, or special (PII, confidential).
   - **Historical Data**: Determine if historical data needs to be ingested and how it differs from current data.
   - **Data Volume**: Plan for incremental or full loads based on data volume.

10. **Frameworks and Standards**:
    - **Company Guidelines**: Follow company-specific frameworks and guidelines for consistency.

#### Conclusion
The video outlines a comprehensive approach to ingesting new data sources, focusing on proper planning, security, and connectivity. By following these guidelines, data engineers can ensure smooth and efficient data ingestion processes in Azure Data Factory.

---
