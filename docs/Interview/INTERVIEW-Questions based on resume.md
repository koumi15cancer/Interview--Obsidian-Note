
1. **Can you walk me through a project where you optimized database queries?**
    
    _Answer_: "Certainly. At NEC Vietnam, I worked on optimizing database queries to improve backend response times. One project involved optimizing SQL queries for a critical application feature. By analyzing query execution plans and identifying bottlenecks, I was able to rewrite queries, add appropriate indexes, and fine-tune database configurations. As a result, we achieved a 30% reduction in backend response times, leading to a smoother user experience."
    
2. **How did you automate database migration tasks using shell scripts?**
    
    _Answer_: "During my time at NEC Vietnam, I automated database migration tasks using shell scripts to ensure environment and platform integrity. I developed scripts to handle schema changes, data migrations, and version control. By automating these tasks, we reduced manual effort and minimized the risk of human error. Additionally, this approach improved team productivity by 60% and allowed us to focus on more value-added activities."
    
3. **Can you describe a situation where you implemented continuous integration and continuous deployment (CI/CD) pipelines?**
    
    _Answer_: "At Mizuho Information & Research Institute Asia Pte. Ltd, I led the implementation of CI/CD pipelines to streamline software release cycles and improve team productivity. We integrated automated testing, code quality checks, and deployment processes into our pipeline using tools like Jenkins and Docker. By automating these processes, we reduced software release cycles by 30% and achieved faster time-to-market while ensuring codebase stability and quality."
    
4. **How did you approach the development of ETL pipelines for data processing?**
    
    _Answer_: "During my internship at Zalopay, I developed ETL pipelines to process and analyze large volumes of data for business insights. I used PySpark for preprocessing and feature extraction, ensuring scalability and performance. Additionally, I incorporated tools like Great Expectations for data quality checks and Airflow for workflow orchestration. By designing and implementing these pipelines, we improved data accuracy, reliability, and the efficiency of our analytics workflows."
    
5. **Tell me about a project where you utilized containerization and orchestration tools like Docker and Kubernetes.**
    
    _Answer_: "In my personal project, I implemented infrastructure services using Docker and Kubernetes to facilitate seamless deployment between local and cloud environments. I containerized microservices using Docker, allowing for consistent deployment across different environments. Additionally, I utilized Kubernetes for orchestration, managing containerized applications, and scaling resources dynamically. This approach improved scalability, reliability, and deployment efficiency for our application."